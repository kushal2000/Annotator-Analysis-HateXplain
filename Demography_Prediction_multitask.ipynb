{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Demography-Prediction-multitask.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brLBPDVfIuuQ"
      },
      "source": [
        "### input - text of the tweet, and outputs are - label, an a demographic feature value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk2RF6PCO2l8"
      },
      "source": [
        "import itertools\n",
        "import spacy\n",
        "import random\n",
        "import os\n",
        "from spacy.util import minibatch, compounding\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount = True)\n",
        "root_path = 'gdrive/My Drive/AI&Ethics/'\n",
        "os.chdir(root_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSBMOPfjeQ1Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c89fd00-eaf1-4a7d-9b1d-b58f3a035c33"
      },
      "source": [
        "!pip -q install datasets\n",
        "!pip -q install sentencepiece==0.1.94\n",
        "# !pip install transformers==4.0.1\n",
        "!pip -q install pytorch-lightning\n",
        "!pip -q install demoji\n",
        "!pip -q install tweet-preprocessor\n",
        "!pip -q install transformers\n",
        "!pip -q install ekphrasis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 194kB 20.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 245kB 41.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 56.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 19.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 849kB 21.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 184kB 53.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 276kB 58.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 829kB 56.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3MB 55.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 296kB 56.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 143kB 56.6MB/s \n",
            "\u001b[?25h  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 17.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 870kB 55.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3MB 54.4MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 184kB 26.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 9.5MB/s \n",
            "\u001b[?25h  Building wheel for ekphrasis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qD-0Zy9eUL_",
        "outputId": "4fc2f6f2-305e-430e-a4d2-afcde92d3aa8"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import json\n",
        "import pickle\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import copy\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, RandomSampler, SequentialSampler, random_split, DataLoader, IterableDataset, ConcatDataset\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import f1_score \n",
        "from tqdm import tqdm\n",
        "import demoji \n",
        "import random\n",
        "demoji.download_codes() \n",
        "import preprocessor as p\n",
        "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
        "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from ekphrasis.dicts.emoticons import emoticons\n",
        "plt.rcParams['figure.figsize'] = [15, 8]\n",
        "plt.rcParams.update({'font.size': 8})\n",
        "RANDOM_SEED = 42\n",
        "model_path = 'ai4bharat/indic-bert'\n",
        "model_path = 'bert-base-uncased'\n",
        "annotator_file = \"data/annotators_demography.csv\"\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading emoji data ...\n",
            "... OK (Got response in 0.16 seconds)\n",
            "Writing emoji data to /root/.demoji/codes.json ...\n",
            "... OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gx8Oic4ERh1c"
      },
      "source": [
        "# Run these"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1jCXp0GeeVI"
      },
      "source": [
        "def random_seed(seed_value, use_cuda):\n",
        "    np.random.seed(seed_value)  \n",
        "    torch.manual_seed(seed_value)  \n",
        "    random.seed(seed_value)\n",
        "    if use_cuda:\n",
        "        torch.cuda.manual_seed(seed_value)\n",
        "        torch.cuda.manual_seed_all(seed_value)  \n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "random_seed(RANDOM_SEED, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twfYH4QMV4Ga"
      },
      "source": [
        "categories = ['Age', 'Country', 'Religion', 'Race', 'Gender']\n",
        "categories_dict = {categories[i]: i for i in range(len(categories))}\n",
        "label_dict = {}\n",
        "dict_label = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uy2yQ6mei2E"
      },
      "source": [
        "class Dataset():\n",
        "    def __init__(self, data, batch_size = 32, train = False):\n",
        "        self.data = data\n",
        "        # self.val_data = val_data\n",
        "        self.batch_size = batch_size                         \n",
        "        self.count_dic = {}\n",
        "        self.train = train\n",
        "        self.inputs, self.labels, self.demographies = self.process_data(self.data)\n",
        "        self.DataLoader = self.get_dataloader(self.inputs, self.labels, self.demographies)\n",
        "        # self.train_dataloader = self.process_data(dataset_file, post_id_divisions_file, 'train')\n",
        "        # self.val_dataloader = self.process_data(dataset_file, post_id_divisions_file, 'test')\n",
        "        # self.test_dataloader = self.process_data(dataset_file, post_id_divisions_file, 'test')\n",
        "\n",
        "    def ek_extra_preprocess(self, text):\n",
        "        remove_words=['<allcaps>','</allcaps>','<hashtag>','</hashtag>','<elongated>','<emphasis>','<repeated>','\\'','s']\n",
        "        word_list=text_processor.pre_process_doc(text)\n",
        "        word_list=list(filter(lambda a: a not in remove_words, word_list)) \n",
        "        sent=\" \".join(word_list)\n",
        "        sent = re.sub(r\"[<\\*>]\", \" \",sent)\n",
        "        return sent\n",
        "\n",
        "    def tokenize(self, sentences, padding = True, max_len = 128):\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)\n",
        "        input_ids, attention_masks, token_type_ids = [], [], []\n",
        "        for sent in sentences:\n",
        "            encoded_dict = tokenizer.encode_plus(sent,\n",
        "                                                    add_special_tokens=True,\n",
        "                                                    max_length=max_len, \n",
        "                                                    padding='max_length', \n",
        "                                                    return_attention_mask = True,\n",
        "                                                    return_tensors = 'pt', \n",
        "                                                    truncation = True)\n",
        "            input_ids.append(encoded_dict['input_ids'])\n",
        "            attention_masks.append(encoded_dict['attention_mask'])\n",
        "        \n",
        "        input_ids = torch.cat(input_ids, dim=0)\n",
        "        attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "        return {'input_ids': input_ids, 'attention_masks': attention_masks}\n",
        "    \n",
        "    def process_data(self, data):\n",
        "        sentences, labels, demographies = [], [], []\n",
        "        print(len(data))\n",
        "\n",
        "        for row in data:\n",
        "\n",
        "            label = row['label']\n",
        "            # label_oh = [0]*3\n",
        "            # label_oh[label] = 1\n",
        "            labels.append(label)\n",
        "            \n",
        "\n",
        "            sentence = ' '.join(row['text'])\n",
        "            sentences.append(sentence)\n",
        "\n",
        "            demography = []\n",
        "\n",
        "            for category in categories:\n",
        "\n",
        "                if category not in label_dict: label_dict[category] = {}\n",
        "                if category not in dict_label: dict_label[category] = {}\n",
        "\n",
        "                if row[category] not in label_dict[category]: \n",
        "                    label_dict[category][row[category]] = len(label_dict[category])\n",
        "                    dict_label[category][label_dict[category][row[category]]] = row[category]\n",
        "                \n",
        "                demography.append(label_dict[category][row[category]])\n",
        "            \n",
        "            demographies.append(demography)\n",
        "\n",
        "        inputs = self.tokenize(sentences)\n",
        "        return inputs, torch.Tensor(labels), torch.Tensor(demographies)\n",
        "    \n",
        "    def get_dataloader(self, inputs, labels, demographies):\n",
        "        data = TensorDataset(inputs['input_ids'], inputs['attention_masks'], labels, demographies)\n",
        "        if self.train:\n",
        "            sampler = RandomSampler(data)\n",
        "        else:\n",
        "            sampler = SequentialSampler(data)\n",
        "        return DataLoader(data, sampler=sampler, batch_size=self.batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrWoEEjMQ-QD",
        "outputId": "f3c0e437-d3c5-46d6-bd8d-53fbea177d38"
      },
      "source": [
        "import json\n",
        "with open('./data/train_demographic.json', 'r') as f:\n",
        "    train_df = json.load(f)\n",
        "train_data = Dataset(train_df, train = True)\n",
        "with open('./data/valid_demographic.json', 'r') as f:\n",
        "    val_df = json.load(f)\n",
        "val_data = Dataset(val_df)\n",
        "with open('./data/test_demographic.json', 'r') as f:\n",
        "    test_df = json.load(f)\n",
        "test_data = Dataset(test_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11553\n",
            "1419\n",
            "1407\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEgZtEa-dYUO",
        "outputId": "08ed1b2b-5ed5-4a53-9069-fd7efcb8251f"
      },
      "source": [
        "categories_count = {category: len(label_dict[category]) for category in categories}\n",
        "categories_count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Age': 6, 'Country': 17, 'Gender': 3, 'Race': 7, 'Religion': 7}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7YVnLcLn_ZX"
      },
      "source": [
        "class SC_weighted_BERT(nn.Module):\n",
        "    def __init__(self, model_path, labels = False, category = 'Age', label_output = False):\n",
        "        super(SC_weighted_BERT, self).__init__()\n",
        "        self.bert = AutoModel.from_pretrained(model_path)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.use_labels = labels\n",
        "        self.num_labels = categories_count[category]\n",
        "        print(self.num_labels)\n",
        "        if labels:\n",
        "            self.classifier = nn.Linear(768 + 3, self.num_labels)\n",
        "        elif label_output:\n",
        "            self.classifier = nn.Linear(768, self.num_labels)\n",
        "            self.classifier2 = nn.Linear(768, 3)\n",
        "        else:\n",
        "            self.classifier = nn.Linear(768, self.num_labels)\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, labels = None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs[1]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        if self.use_labels:\n",
        "            pooled_output = torch.cat([pooled_output, labels], dim = 1)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        hate_pred = self.classifier2(pooled_output)\n",
        "\n",
        "        outputs1 = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
        "        outputs2 = (hate_pred,) + outputs[2:]  # add hidden states and attention if they are here\n",
        "        return outputs1, outputs2  # (loss), logits, (hidden_states), (attentions) for each"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKPMl_fWKZyn"
      },
      "source": [
        "import copy\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        " \n",
        "def get_predicted(preds):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    return pred_flat\n",
        " \n",
        "def evaluate(test_dataloader, model, category = 'Age'):\n",
        "    model.eval()\n",
        "    y_preds, y_test = np.array([]), np.array([])\n",
        "\n",
        "    for batch in test_dataloader:\n",
        "        b_input_ids, b_input_mask, b_labels, b_demographies = batch[0].to(device), batch[1].to(device), batch[2].to(device).long(), batch[3].to(device).long()\n",
        "        with torch.no_grad():        \n",
        "            ypred,_ = model(b_input_ids, b_input_mask)\n",
        "        ypred = ypred[0].cpu().numpy()\n",
        "        label_ids = b_demographies[:, categories_dict[category]].to('cpu').numpy()\n",
        "        y_preds = np.hstack((y_preds, get_predicted(ypred)))\n",
        "        y_test = np.hstack((y_test, label_ids))\n",
        "\n",
        "    score = accuracy_score(y_test, y_preds)\n",
        "    report = classification_report(y_test, y_preds)\n",
        "    print(report)\n",
        "    return score, y_preds, y_test\n",
        " \n",
        "def train(training_dataloader, validation_dataloader, model, filepath = None, weights = None, learning_rate = 2e-5, epochs = 1, print_every = 100, category = 'Age'):\n",
        "    total_steps = len(training_dataloader) * epochs\n",
        "    no_decay = ['bias', 'LayerNorm.weight', 'LayerNorm.bias']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "    ]\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps = 1e-8)\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                                num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                                num_training_steps = total_steps)\n",
        "    \n",
        "    best_weighted_f1 = 0\n",
        "    best_model = None\n",
        "    # current_epoch, best_weighted_f1 = load_metrics(filepath, model, optimizer)\n",
        "    if weights == None:\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "    else:\n",
        "        criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "    for epoch_i in tqdm(range(0, epochs)):\n",
        "        model.train()\n",
        "        for step, batch in enumerate(training_dataloader):\n",
        "            b_input_ids, b_input_mask, b_labels, b_demographies = batch[0].to(device), batch[1].to(device), batch[2].to(device).long(), batch[3].to(device).long()\n",
        "            # print(b_demographies[:, categories_dict[category]])\n",
        "            outputs1, outputs2 = model(b_input_ids, b_input_mask)\n",
        "            loss = (criterion(outputs1[0], b_demographies[:, categories_dict[category]]) + criterion(outputs2[0], b_labels))/2\n",
        " \n",
        "            if step%print_every == 0:\n",
        "                print(loss.item())\n",
        " \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        " \n",
        "        print('### Validation Set Stats')\n",
        "        weighted_f1, ypred, ytest = evaluate(validation_dataloader, model, category = category)\n",
        "        print(\"  Macro F1: {0:.3f}\".format(weighted_f1))\n",
        "        if weighted_f1 > best_weighted_f1:\n",
        "            best_weighted_f1 = weighted_f1\n",
        "            best_model = copy.deepcopy(model)\n",
        "            # save_metrics(filepath, epoch_i, model, optimizer, weighted_f1)\n",
        "        \n",
        "    return best_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dRMppIjb2z2",
        "outputId": "0c7d2f2e-20c3-41e7-974f-7593a6a5718f"
      },
      "source": [
        "pkl_filename = 'results_demographies_multitask.pkl'\n",
        "\n",
        "try:\n",
        "    with open(pkl_filename, 'rb') as f:\n",
        "        results = pickle.load(f)\n",
        "except:\n",
        "    results = {}\n",
        "    with open(pkl_filename, 'wb') as f:\n",
        "        pickle.dump(results, f)\n",
        "   \n",
        "\n",
        "categories = ['Age', 'Country', 'Religion', 'Race', 'Gender']\n",
        "class_names = ['Race'] #Gender, Age, Country, Religion, Race\n",
        "\n",
        "for c in class_names:\n",
        "    # if c in results: continue\n",
        "    # else: results[c] = {}\n",
        "\n",
        "    # model = SC_weighted_BERT(model_path, labels = False, category = c).to(device)\n",
        "    # model = train(train_data.DataLoader, val_data.DataLoader, model, None, epochs = 5, category = c)\n",
        "    # _, ypreds, ytest = evaluate(test_data.DataLoader, model)\n",
        "    # acc = accuracy_score(ytest, ypreds)\n",
        "    # f1 = f1_score(ytest, ypreds, average = 'macro')\n",
        "\n",
        "    # with open('results_demographies.pkl', 'rb') as f:\n",
        "    #     results = pickle.load(f)\n",
        "    # if c not in results: results[c] = {}\n",
        "    # results[c]['no_labels'] = {'f1': f1, 'acc':acc}\n",
        "    # with open('results_demographies.pkl', 'wb') as f:\n",
        "    #     pickle.dump(results, f)\n",
        "\n",
        "    model = SC_weighted_BERT(model_path, category = c, label_output = True).to(device)\n",
        "    model = train(train_data.DataLoader, val_data.DataLoader, model, None, epochs = 5, category = c)\n",
        "    _, ypreds, ytest = evaluate(test_data.DataLoader, model, category = c)\n",
        "    acc = accuracy_score(ytest, ypreds)\n",
        "    f1 = f1_score(ytest, ypreds, average = 'macro')\n",
        "\n",
        "    with open(pkl_filename, 'rb') as f:\n",
        "        results = pickle.load(f)\n",
        "    if c not in results: results[c] = {}\n",
        "    results[c]['used_labels'] = {'f1': f1, 'acc':acc}\n",
        "    with open(pkl_filename, 'wb') as f:\n",
        "        pickle.dump(results, f)\n",
        "\n",
        "    print(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.3720755577087402\n",
            "1.0377540588378906\n",
            "0.9681323766708374\n",
            "1.0065374374389648\n",
            "### Validation Set Stats\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00       191\n",
            "         1.0       0.00      0.00      0.00       131\n",
            "         2.0       0.67      1.00      0.80       944\n",
            "         3.0       0.00      0.00      0.00        65\n",
            "         4.0       0.00      0.00      0.00        66\n",
            "         5.0       0.00      0.00      0.00         9\n",
            "         6.0       0.00      0.00      0.00        13\n",
            "\n",
            "    accuracy                           0.67      1419\n",
            "   macro avg       0.10      0.14      0.11      1419\n",
            "weighted avg       0.44      0.67      0.53      1419\n",
            "\n",
            "  Macro F1: 0.665\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 1/5 [04:06<16:26, 246.63s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.0324156284332275\n",
            "0.9432137608528137\n",
            "0.8170341849327087\n",
            "0.9632314443588257\n",
            "### Validation Set Stats\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00       191\n",
            "         1.0       0.00      0.00      0.00       131\n",
            "         2.0       0.67      1.00      0.80       944\n",
            "         3.0       0.00      0.00      0.00        65\n",
            "         4.0       0.00      0.00      0.00        66\n",
            "         5.0       0.00      0.00      0.00         9\n",
            "         6.0       0.00      0.00      0.00        13\n",
            "\n",
            "    accuracy                           0.67      1419\n",
            "   macro avg       0.10      0.14      0.11      1419\n",
            "weighted avg       0.44      0.67      0.53      1419\n",
            "\n",
            "  Macro F1: 0.665\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 2/5 [08:25<12:30, 250.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.101189374923706\n",
            "0.824062168598175\n",
            "0.9401799440383911\n",
            "0.8724303245544434\n",
            "### Validation Set Stats\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00       191\n",
            "         1.0       0.00      0.00      0.00       131\n",
            "         2.0       0.67      1.00      0.80       944\n",
            "         3.0       0.00      0.00      0.00        65\n",
            "         4.0       0.00      0.00      0.00        66\n",
            "         5.0       0.00      0.00      0.00         9\n",
            "         6.0       0.00      0.00      0.00        13\n",
            "\n",
            "    accuracy                           0.67      1419\n",
            "   macro avg       0.10      0.14      0.11      1419\n",
            "weighted avg       0.44      0.67      0.53      1419\n",
            "\n",
            "  Macro F1: 0.665\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 3/5 [12:45<08:26, 253.09s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.7246900796890259\n",
            "0.7317758798599243\n",
            "0.6237325072288513\n",
            "0.7887852191925049\n",
            "### Validation Set Stats\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00       191\n",
            "         1.0       0.00      0.00      0.00       131\n",
            "         2.0       0.67      1.00      0.80       944\n",
            "         3.0       0.00      0.00      0.00        65\n",
            "         4.0       0.00      0.00      0.00        66\n",
            "         5.0       0.00      0.00      0.00         9\n",
            "         6.0       0.00      0.00      0.00        13\n",
            "\n",
            "    accuracy                           0.67      1419\n",
            "   macro avg       0.10      0.14      0.11      1419\n",
            "weighted avg       0.44      0.67      0.53      1419\n",
            "\n",
            "  Macro F1: 0.665\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 4/5 [17:04<04:14, 254.95s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.581902027130127\n",
            "0.6603726744651794\n",
            "0.8345416188240051\n",
            "0.5548633337020874\n",
            "### Validation Set Stats\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00       191\n",
            "         1.0       0.00      0.00      0.00       131\n",
            "         2.0       0.67      1.00      0.80       944\n",
            "         3.0       0.00      0.00      0.00        65\n",
            "         4.0       0.00      0.00      0.00        66\n",
            "         5.0       0.00      0.00      0.00         9\n",
            "         6.0       0.00      0.00      0.00        13\n",
            "\n",
            "    accuracy                           0.67      1419\n",
            "   macro avg       0.10      0.14      0.11      1419\n",
            "weighted avg       0.44      0.67      0.53      1419\n",
            "\n",
            "  Macro F1: 0.665\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [21:23<00:00, 256.72s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00       185\n",
            "         1.0       0.00      0.00      0.00       122\n",
            "         2.0       0.66      1.00      0.80       931\n",
            "         3.0       0.00      0.00      0.00        71\n",
            "         4.0       0.00      0.00      0.00        79\n",
            "         5.0       0.00      0.00      0.00         9\n",
            "         6.0       0.00      0.00      0.00        10\n",
            "\n",
            "    accuracy                           0.66      1407\n",
            "   macro avg       0.09      0.14      0.11      1407\n",
            "weighted avg       0.44      0.66      0.53      1407\n",
            "\n",
            "{'Gender': {'used_labels': {'f1': 0.29755199418419903, 'acc': 0.5600568585643213}}, 'Age': {'used_labels': {'f1': 0.10975912702946833, 'acc': 0.4534470504619758}}, 'Country': {'used_labels': {'f1': 0.06122247457292386, 'acc': 0.6609808102345416}}, 'Religion': {'used_labels': {'f1': 0.10815244825845534, 'acc': 0.6090973702914001}}, 'Race': {'used_labels': {'f1': 0.11377245508982035, 'acc': 0.6616915422885572}}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOAhm2lh8srh"
      },
      "source": [
        "# for c in class_names:\n",
        "#     _, ypreds, ytest = evaluate(test_data.DataLoader, model, category = c)\n",
        "#     acc = accuracy_score(ytest, ypreds)\n",
        "#     f1 = f1_score(ytest, ypreds, average = 'macro')\n",
        "\n",
        "#     results[c]['used_labels'] = {'f1': f1, 'acc':acc}\n",
        "#     with open(pkl_filename, 'wb') as f:\n",
        "#         pickle.dump(results, f)\n",
        "\n",
        "#     print(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfZvkdL603sB"
      },
      "source": [
        "# with open('results_demographies.pkl', 'rb') as f:\n",
        "#     a__ = pickle.load(f)\n",
        "# a__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIqvC1Rg1Cf1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}