{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Dempgraphy-Prediction","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"sk2RF6PCO2l8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617374993220,"user_tz":-330,"elapsed":2668,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"495c3d99-4782-446e-c494-d34d921a3542"},"source":["import itertools\n","import spacy\n","import random\n","import os\n","from spacy.util import minibatch, compounding\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount = True)\n","root_path = 'gdrive/My Drive/AI&Ethics/'\n","os.chdir(root_path)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BSBMOPfjeQ1Y","executionInfo":{"status":"ok","timestamp":1617361534099,"user_tz":-330,"elapsed":19214,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}}},"source":["!pip -q install datasets\n","!pip -q install sentencepiece==0.1.94\n","# !pip install transformers==4.0.1\n","!pip -q install pytorch-lightning\n","!pip -q install demoji\n","!pip -q install tweet-preprocessor\n","!pip -q install transformers\n","!pip -q install ekphrasis"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5qD-0Zy9eUL_","executionInfo":{"status":"ok","timestamp":1617374999530,"user_tz":-330,"elapsed":3769,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"e8f621ae-612c-4d69-f92a-c07405529011"},"source":["import numpy as np\n","import pandas as pd\n","import re\n","from transformers import AutoModel, AutoTokenizer\n","import json\n","import pickle\n","import torch.nn as nn\n","import torch\n","import copy\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from torch.utils.data import TensorDataset, RandomSampler, SequentialSampler, random_split, DataLoader, IterableDataset, ConcatDataset\n","import sklearn\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","from sklearn.metrics import f1_score \n","from tqdm import tqdm\n","import demoji \n","import random\n","demoji.download_codes() \n","import preprocessor as p\n","from ekphrasis.classes.preprocessor import TextPreProcessor\n","from ekphrasis.classes.tokenizer import SocialTokenizer\n","from sklearn.metrics import classification_report, accuracy_score\n","from ekphrasis.dicts.emoticons import emoticons\n","plt.rcParams['figure.figsize'] = [15, 8]\n","plt.rcParams.update({'font.size': 8})\n","RANDOM_SEED = 42\n","model_path = 'ai4bharat/indic-bert'\n","model_path = 'bert-base-uncased'\n","annotator_file = \"data/annotators_demography.csv\"\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Downloading emoji data ...\n","... OK (Got response in 0.16 seconds)\n","Writing emoji data to /root/.demoji/codes.json ...\n","... OK\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gx8Oic4ERh1c"},"source":["# Run these"]},{"cell_type":"code","metadata":{"id":"V1jCXp0GeeVI","executionInfo":{"status":"ok","timestamp":1617375002657,"user_tz":-330,"elapsed":1152,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}}},"source":["def random_seed(seed_value, use_cuda):\n","    np.random.seed(seed_value)  \n","    torch.manual_seed(seed_value)  \n","    random.seed(seed_value)\n","    if use_cuda:\n","        torch.cuda.manual_seed(seed_value)\n","        torch.cuda.manual_seed_all(seed_value)  \n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","random_seed(RANDOM_SEED, True)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"twfYH4QMV4Ga","executionInfo":{"status":"ok","timestamp":1617375003248,"user_tz":-330,"elapsed":1554,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}}},"source":["categories = ['Age', 'Country', 'Religion', 'Race', 'Gender']\n","categories_dict = {categories[i]: i for i in range(len(categories))}\n","label_dict = {}\n","dict_label = {}"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"4uy2yQ6mei2E","executionInfo":{"status":"ok","timestamp":1617375003249,"user_tz":-330,"elapsed":1430,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}}},"source":["class Dataset():\n","    def __init__(self, data, batch_size = 32, train = False):\n","        self.data = data\n","        # self.val_data = val_data\n","        self.batch_size = batch_size                         \n","        self.count_dic = {}\n","        self.train = train\n","        self.inputs, self.labels, self.demographies = self.process_data(self.data)\n","        self.DataLoader = self.get_dataloader(self.inputs, self.labels, self.demographies)\n","        # self.train_dataloader = self.process_data(dataset_file, post_id_divisions_file, 'train')\n","        # self.val_dataloader = self.process_data(dataset_file, post_id_divisions_file, 'test')\n","        # self.test_dataloader = self.process_data(dataset_file, post_id_divisions_file, 'test')\n","\n","    def ek_extra_preprocess(self, text):\n","        remove_words=['<allcaps>','</allcaps>','<hashtag>','</hashtag>','<elongated>','<emphasis>','<repeated>','\\'','s']\n","        word_list=text_processor.pre_process_doc(text)\n","        word_list=list(filter(lambda a: a not in remove_words, word_list)) \n","        sent=\" \".join(word_list)\n","        sent = re.sub(r\"[<\\*>]\", \" \",sent)\n","        return sent\n","\n","    def tokenize(self, sentences, padding = True, max_len = 128):\n","        tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)\n","        input_ids, attention_masks, token_type_ids = [], [], []\n","        for sent in sentences:\n","            encoded_dict = tokenizer.encode_plus(sent,\n","                                                    add_special_tokens=True,\n","                                                    max_length=max_len, \n","                                                    padding='max_length', \n","                                                    return_attention_mask = True,\n","                                                    return_tensors = 'pt', \n","                                                    truncation = True)\n","            input_ids.append(encoded_dict['input_ids'])\n","            attention_masks.append(encoded_dict['attention_mask'])\n","        \n","        input_ids = torch.cat(input_ids, dim=0)\n","        attention_masks = torch.cat(attention_masks, dim=0)\n","\n","        return {'input_ids': input_ids, 'attention_masks': attention_masks}\n","    \n","    def process_data(self, data):\n","        sentences, labels, demographies = [], [], []\n","        print(len(data))\n","\n","        for row in data:\n","\n","            label = row['label']\n","            label_oh = [0]*3\n","            label_oh[label] = 1\n","            labels.append(label_oh)\n","            \n","\n","            sentence = ' '.join(row['text'])\n","            sentences.append(sentence)\n","\n","            demography = []\n","\n","            for category in categories:\n","\n","                if category not in label_dict: label_dict[category] = {}\n","                if category not in dict_label: dict_label[category] = {}\n","\n","                if row[category] not in label_dict[category]: \n","                    label_dict[category][row[category]] = len(label_dict[category])\n","                    dict_label[category][label_dict[category][row[category]]] = row[category]\n","                \n","                demography.append(label_dict[category][row[category]])\n","            \n","            demographies.append(demography)\n","\n","        inputs = self.tokenize(sentences)\n","        return inputs, torch.Tensor(labels), torch.Tensor(demographies)\n","    \n","    def get_dataloader(self, inputs, labels, demographies):\n","        data = TensorDataset(inputs['input_ids'], inputs['attention_masks'], labels, demographies)\n","        if self.train:\n","            sampler = RandomSampler(data)\n","        else:\n","            sampler = SequentialSampler(data)\n","        return DataLoader(data, sampler=sampler, batch_size=self.batch_size)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xrWoEEjMQ-QD","executionInfo":{"status":"ok","timestamp":1617375017710,"user_tz":-330,"elapsed":15637,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"ed2e0a16-4a36-41d6-ab8e-d224a96f647d"},"source":["import json\n","with open('./data/train_demographic.json', 'r') as f:\n","    train_df = json.load(f)\n","train_data = Dataset(train_df, train = True)\n","with open('./data/valid_demographic.json', 'r') as f:\n","    val_df = json.load(f)\n","val_data = Dataset(val_df)\n","with open('./data/test_demographic.json', 'r') as f:\n","    test_df = json.load(f)\n","test_data = Dataset(test_df)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["11553\n","1419\n","1407\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IEgZtEa-dYUO","executionInfo":{"status":"ok","timestamp":1617375017711,"user_tz":-330,"elapsed":15077,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"13a720e8-477f-4654-8a8e-1bcf1d457bf8"},"source":["categories_count = {category: len(label_dict[category]) for category in categories}\n","categories_count"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Age': 6, 'Country': 17, 'Gender': 3, 'Race': 7, 'Religion': 7}"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"j7YVnLcLn_ZX","executionInfo":{"status":"ok","timestamp":1617375017711,"user_tz":-330,"elapsed":14675,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}}},"source":["class SC_weighted_BERT(nn.Module):\n","    def __init__(self, model_path, labels = False, category = 'Age'):\n","        super(SC_weighted_BERT, self).__init__()\n","        self.bert = AutoModel.from_pretrained(model_path)\n","        self.dropout = nn.Dropout(0.1)\n","        self.use_labels = labels\n","        self.num_labels = categories_count[category]\n","        print(self.num_labels)\n","        if labels:\n","            self.classifier = nn.Linear(768 + 3, self.num_labels)\n","        else:\n","            self.classifier = nn.Linear(768, self.num_labels)\n","\n","    def forward(self, input_ids=None, attention_mask=None, labels = None):\n","        outputs = self.bert(input_ids, attention_mask=attention_mask)\n","        pooled_output = outputs[1]\n","        pooled_output = self.dropout(pooled_output)\n","        if self.use_labels:\n","            pooled_output = torch.cat([pooled_output, labels], dim = 1)\n","        logits = self.classifier(pooled_output)\n","        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n","        return outputs  # (loss), logits, (hidden_states), (attentions)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"SKPMl_fWKZyn","executionInfo":{"status":"ok","timestamp":1617375017712,"user_tz":-330,"elapsed":14152,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}}},"source":["import copy\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"," \n","def get_predicted(preds):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    return pred_flat\n"," \n","def evaluate(test_dataloader, model, category = 'Age'):\n","    model.eval()\n","    y_preds, y_test = np.array([]), np.array([])\n","\n","    for batch in test_dataloader:\n","        b_input_ids, b_input_mask, b_labels, b_demographies = batch[0].to(device), batch[1].to(device), batch[2].to(device).long(), batch[3].to(device).long()\n","        with torch.no_grad():        \n","            ypred = model(b_input_ids, b_input_mask, b_labels)\n","        ypred = ypred[0].cpu().numpy()\n","        label_ids = b_demographies[:, categories_dict[category]].to('cpu').numpy()\n","        y_preds = np.hstack((y_preds, get_predicted(ypred)))\n","        y_test = np.hstack((y_test, label_ids))\n","\n","    score = accuracy_score(y_test, y_preds)\n","    report = classification_report(y_test, y_preds)\n","    print(report)\n","    return score, y_preds, y_test\n"," \n","def train(training_dataloader, validation_dataloader, model, filepath = None, weights = None, learning_rate = 2e-5, epochs = 1, print_every = 100, category = 'Age'):\n","    total_steps = len(training_dataloader) * epochs\n","    no_decay = ['bias', 'LayerNorm.weight', 'LayerNorm.bias']\n","    optimizer_grouped_parameters = [\n","        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","    ]\n","    optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps = 1e-8)\n","    scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                                num_warmup_steps = 0, # Default value in run_glue.py\n","                                                num_training_steps = total_steps)\n","    \n","    best_weighted_f1 = 0\n","    best_model = None\n","    # current_epoch, best_weighted_f1 = load_metrics(filepath, model, optimizer)\n","    if weights == None:\n","        criterion = nn.CrossEntropyLoss()\n","    else:\n","        criterion = nn.CrossEntropyLoss(weight=weights)\n","    for epoch_i in tqdm(range(0, epochs)):\n","        model.train()\n","        for step, batch in enumerate(training_dataloader):\n","            b_input_ids, b_input_mask, b_labels, b_demographies = batch[0].to(device), batch[1].to(device), batch[2].to(device).long(), batch[3].to(device).long()\n","            # print(b_demographies[:, categories_dict[category]])\n","            outputs = model(b_input_ids, b_input_mask, b_labels)\n","            loss = criterion(outputs[0], b_demographies[:, categories_dict[category]])\n"," \n","            if step%print_every == 0:\n","                print(loss.item())\n"," \n","            optimizer.zero_grad()\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","            optimizer.step()\n","            scheduler.step()\n"," \n","        print('### Validation Set Stats')\n","        weighted_f1, ypred, ytest = evaluate(validation_dataloader, model, category = category)\n","        print(\"  Macro F1: {0:.3f}\".format(weighted_f1))\n","        if weighted_f1 > best_weighted_f1:\n","            best_weighted_f1 = weighted_f1\n","            best_model = copy.deepcopy(model)\n","            # save_metrics(filepath, epoch_i, model, optimizer, weighted_f1)\n","        \n","    return best_model"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9dRMppIjb2z2","outputId":"4a6be518-882e-4d97-fd3e-a2d88aabf96a"},"source":["try:\n","    with open('results_demographies.pkl', 'rb') as f:\n","        results = pickle.load(f)\n","except:\n","    results = {}\n","    with open('results_demographies.pkl', 'wb') as f:\n","        pickle.dump(results, f)\n","   \n","\n","categories = ['Age', 'Country', 'Religion', 'Race', 'Gender']\n","class_names = ['Gender']\n","\n","for c in class_names:\n","    # if c in results: continue\n","    # else: results[c] = {}\n","\n","    # model = SC_weighted_BERT(model_path, labels = False, category = c).to(device)\n","    # model = train(train_data.DataLoader, val_data.DataLoader, model, None, epochs = 5, category = c)\n","    # _, ypreds, ytest = evaluate(test_data.DataLoader, model)\n","    # acc = accuracy_score(ytest, ypreds)\n","    # f1 = f1_score(ytest, ypreds, average = 'macro')\n","\n","    # with open('results_demographies.pkl', 'rb') as f:\n","    #     results = pickle.load(f)\n","    # if c not in results: results[c] = {}\n","    # results[c]['no_labels'] = {'f1': f1, 'acc':acc}\n","    # with open('results_demographies.pkl', 'wb') as f:\n","    #     pickle.dump(results, f)\n","\n","    model = SC_weighted_BERT(model_path, labels = True, category = c).to(device)\n","    model = train(train_data.DataLoader, val_data.DataLoader, model, None, epochs = 5, category = c)\n","    _, ypreds, ytest = evaluate(test_data.DataLoader, model)\n","    acc = accuracy_score(ytest, ypreds)\n","    f1 = f1_score(ytest, ypreds, average = 'macro')\n","\n","    with open('results_demographies.pkl', 'rb') as f:\n","        results = pickle.load(f)\n","    if c not in results: results[c] = {}\n","    results[c]['used_labels'] = {'f1': f1, 'acc':acc}\n","    with open('results_demographies.pkl', 'wb') as f:\n","        pickle.dump(results, f)\n","\n","    print(results)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["3\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/5 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["1.105813980102539\n","0.8579772710800171\n","0.88270103931427\n","0.7879781126976013\n","### Validation Set Stats\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","         0.0       0.41      0.26      0.31       563\n","         1.0       0.59      0.77      0.67       823\n","         2.0       0.00      0.00      0.00        33\n","\n","    accuracy                           0.55      1419\n","   macro avg       0.33      0.34      0.33      1419\n","weighted avg       0.50      0.55      0.51      1419\n","\n","  Macro F1: 0.545\n"],"name":"stdout"},{"output_type":"stream","text":["\r 20%|██        | 1/5 [04:12<16:50, 252.61s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.7665758728981018\n","0.7116250991821289\n","0.8140242099761963\n","0.8157234787940979\n","### Validation Set Stats\n","              precision    recall  f1-score   support\n","\n","         0.0       0.43      0.47      0.45       563\n","         1.0       0.61      0.59      0.60       823\n","         2.0       0.00      0.00      0.00        33\n","\n","    accuracy                           0.53      1419\n","   macro avg       0.35      0.35      0.35      1419\n","weighted avg       0.52      0.53      0.53      1419\n","\n","  Macro F1: 0.530\n"],"name":"stdout"},{"output_type":"stream","text":["\r 40%|████      | 2/5 [08:27<12:39, 253.23s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.6809200048446655\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wOAhm2lh8srh"},"source":[""],"execution_count":null,"outputs":[]}]}